\documentclass[letterpaper]{article}
\usepackage[pass,showframe]{geometry}

\usepackage{ijcai17}
\usepackage{times}
\usepackage{graphicx}
\usepackage{cleveref}

\usepackage[ruled,vlined]{algorithm2e}
\usepackage{MnSymbol,wasysym}
\usepackage{latexsym}

\usepackage{tikz}

\usetikzlibrary{graphs}

\newcommand{\citet}[1]{\citeauthor{#1} \shortcite{#1}}
\newcommand{\citep}[1]{\cite{#1}}

\DeclareMathOperator{\V}{V}
\DeclareMathOperator{\E}{E}

\newcommand{\examplexG}[5] {
    \begin{minipage}{.2\textwidth}
    \tikz {
        \graph [nodes={draw, circle, minimum width=.6cm}, circular placement, radius=1cm,
                clockwise=5] {
                    1[label=90:#1],2[label=0:#2],3[label=0:#3],4[label=180:#4],5[label=180:#5];
            1--4; 1--5; 2--3; 2--5; 3--5;
        };
    }
    \end{minipage}
}
\newcommand{\examplexH}[6] {
    \begin{minipage}{.2\textwidth}
    \tikz {
        \graph [nodes={draw, circle, minimum width=.6cm}, circular placement, radius=1.1cm,
                clockwise=6, phase=60] {
                    a[label=0:#1],b[label=0:#2],c[label=0:#3],d[label=180:#4],e[label=180:#5],f[label=180:#6];
            a--b; a--c; a--e; b--d; b--f; c--d; c--e; c--f; d--f; e--f;
        };
    }
    \end{minipage}
}

\title{A Partitioning Algorithm for Maximum Common (Connected) Subgraphs\thanks{This work
was supported by the Engineering and Physical Sciences Research Council [grant
numbers EP/K503058/1 and EP/M508056/1]}}
\author{Ciaran McCreesh \and Patrick Prosser \and James Trimble \\
University of Glasgow, Glasgow, Scotland \\
j.trimble.1@research.gla.ac.uk}

\begin{document}

\maketitle

\begin{abstract}
    We came up with an important new algorithm for the maximum common (connected)
    subgraph problem. This is an important problem, with at least two important
    applications.
\end{abstract}

\section{Introduction}

\citet{UpcomingAAAIPaper}

\citet{DBLP:conf/cp/McCreeshNPS16}

\citet{DBLP:conf/cp/NdiayeS11}

Given graphs $G=(\V(G), \E(G))$ and $H=(\V(H), \E(H))$, the \emph{Maximum Common
Subgraph (MCS)} problem is to find a graph with as many vertices as possible
that is isomorphic to induced subgraphs of both $G$ and $H$. Equivalently, MCS
is the problem of finding a maximum-cardinality set of pairs $M = \{(v_1, w_1),
\dots, (v_{|M|}, w_{|M|})\}$, with $v_i \in V(G)$ and $v_i \in V(H)$ for all $i$,
such that for each pair $i,j$ ($1 \leq i < j
\leq |M|$), $v_i$ and $v_j$ are adjacent in $G$ if and only if $w_i$ and $w_j$
are adjacent in $H$.

The most successful existing approaches to optimally solving MCS are
reformulation to the maximum clique problem and constraint programming
\cite{DBLP:conf/cp/McCreeshNPS16}. In this paper, we introduce a new branch and bound
algorithm for MCS which does not require a domain to be explicity maintained in
memory for each vertex in $\V(G)$. The algorithm maintains labellings of the
unmatched vertices in $\V(G)$ and $\V(H)$ such that a pair $(v, w)$ with $v \in \V(G)$
and $w \in \V(H)$ can be added to the matching if and only if $v$ and $w$ have the
same label.

\section{Preliminaries}

Let $N(v, G)$ denote the neighbourhood of a vertex $v$ in a graph $G$.  We
extend this notation to denote the set of vertices that are adjacent to all
vertices in a set $U$: $N(U, G) = \bigcap_{v \in U} N_G(v)$.

\section{Walkthrough}

Suppose we are given the graphs $G$ and $H$ in Figure~\ref{fig:alg1}.  Graphs $G$ and $H$
have no common subgraph with five vertices. However, they do have common
subgraphs with four vertices; the mapping $\{1a, 2f, 3d, 5b\}$ is one example.

\begin{figure}[ht]
\centering
    \examplexG{}{}{}{}{}
    \examplexH{}{}{}{}{}{}
\caption{Graphs $G$ and $H$}
\label{fig:alg1}
\end{figure}

The algorithm proceeds by building up a mapping $M$, starting with the empty
mapping $\{\}$. Begin by (arbitrarily) mapping vertex $1$ in $G$ to vertex $a$
in $H$, giving $M=\{1a\}$.  Label each unmatched vertex according to whether it
is adjacent to $1$ (in $G$) or $a$ (in $H$), as shown in Figure~\ref{fig:alg2}.
Adjacent vertices have label 1; non-adjacent vertices have label 0.  It is
straightforward to see that we can extend $M$ with a vertex mapping $vw$, with
$v \in \V(G)$ and $w \in \V(H)$, if and only if $v$ and $w$ have the same label.  This
property is the algorithm's key invariant.

\begin{figure}[ht]
\centering
    \examplexG{$(1a)$}{0}{0}{1}{1}
    \examplexH{$(1a)$}{1}{1}{0}{1}{0}
\caption{Step 2}
\label{fig:alg2}
\end{figure}

Next, extend the mapping by pairing a vertex in $G$ with a vertex in $H$ of the
same label; we will choose to map vertex $2$ to vertex $d$, giving $M=\{1a,
2d\}$ (Figure~\ref{fig:alg3}).  Each unmatched vertex $v \in \V(G)$ is labelled
with a two-character bit string, indicating whether $v$ is adjacent to each of
the two matched vertices in $\V(G)$ (vertices $1$ and $2$).  For example, vertex
$3$ is labelled $01$, indicating that it is not adjacent to $1$ but is adjacent
to $2$.  Labels are given to vertices in $\V(H)$ in a similar fashion, showing
whether each vertex is adjacent to $a$ and $d$.

Observe that our invariant is maintained: we can extend $M$ by a vertex pairing if
and only if the two vertices have the same colour.

\begin{figure}[ht]
\centering
    \examplexG{$(1a)$}{$(2d)$}{01}{10}{11}
    \examplexH{$(1a)$}{11}{11}{$(2d)$}{10}{01}
\caption{Step 3}
\label{fig:alg3}
\end{figure}

The algorithm proceeds by backtracking search. When we have explored the full
search space of matchings containing $\{1a, 2d\}$, we try reassigning $2$ to
$f$.  Since $d$ and $f$ are the only vertices to which $2$ can be matched given
the decision to match $1$ to $a$, we lastly explore the possibility that $2$ is
left unmatched, by giving $2$ the label $\bot$ and selecting another vertex in
$\V(G)$ to assign.



\section{The Lilybank Algorithm}

\begin{algorithm}
\DontPrintSemicolon
\nl $expand(\mathit{future},matching)$ \;
\nl \Begin{
\nl \lIf {$future = \emptyset$ \bf{and} $|matching|  > |incumbent|$}{$save(matching)$}
\nl \lIf {$future = \emptyset$}{return}
\nl $bestFuture \gets 0$ \;
\nl \lFor {$\langle P,T \rangle \in future$}{$bestFuture \gets bestFuture + min(|P|,|T|)$}
\nl \lIf {$|matching|  + bestFuture \leq |incumbent|$}{return}
\bigskip
\nl $\langle P,T \rangle \gets select(future)$ \;
\nl $v \gets select(P)$ \;
\nl \For {$w \in T$}{
\nl    $matching \gets matching + (v,w)$\;
\nl    \bf{Let} $future^{'} \gets \emptyset$ \;
\nl    \For {$\langle P^{'},T'^{'}\rangle \in future$}{
\nl        \bf{Let} $P^{''} \gets P^{'} \cap N(v,G) \setminus \{v\}$ \;
\nl        \bf{Let} $T^{''} \gets T^{'} \cap N(w,H) \setminus \{w\}$ \;
\nl        \lIf {$P^{''} \neq \emptyset$ \bf{and} $T^{''} \neq \emptyset$}{$future^{'} \gets future^{'} + \langle P^{''} , T^{''} \rangle$}
\nl        \bf{Let} $P^{''} \gets P^{'} \cap N(v,\overline{G}) \setminus \{v\}$ \;
\nl        \bf{Let} $T^{''} \gets T^{'} \cap N(w,\overline{H}) \setminus \{w\}$ \;
\nl        \lIf {$P^{''} \neq \emptyset$ \bf{and} $T^{''} \neq \emptyset$}{$future^{'} \gets future^{'} + \langle P^{''} , T^{''} \rangle$}
       }
\nl   $expand(future^{'},matching)$ \;
\nl   $matching \gets matching \setminus \{(v,w)\}$ \;
  }
\nl $P \gets P \setminus \{v\}$\;
\nl \lIf {$P = \emptyset$} {$future \gets future \setminus \{\langle P,T \rangle \}$}
\nl $expand(future,matching)$ \;
}
\;
\nl $Split(G,H)$ \;
\nl \Begin{
\nl $incumbent \gets \emptyset$ \;
\nl $expand(\{\langle V(G),V(H) \rangle \},\emptyset)$ \;
\nl return $|incubent|$ \;
}
\caption{Lilybank splitting algorithm}
\label{jtAlg}
\end{algorithm}

\noindent
Now, let's try and explain this. First, assume we have two graph G and H and there are no more vertices in G than in H (think of G as the pattern graph and H as the target).
future is a list of pairs, where the first element of a pair is a set of pattern vertices P and the second is a set of target vertices T. It is assumed that each pattern vertex in P 
might be matched with any (all) of the target vertices in T, or be unmatched. Therefore we start our search via the function LilybankSplit (line 26). This returns an integer, the size of the largest matching.
In line 29 a call is made to expand, where we have as arguments a list of pairs (called future, line 1) and a set of pairs of the form (v,w) where pattern vertex v is matched to target vertex w.

\bigskip
\noindent
We now focus on expand (line (1)). This is initially called (line 29) with the future as a list containing the single pair $\langle V(G),V(H) \rangle$. Lines 4 to 7 define the conditions 
where we return, i.e. when the incumbent cannot be improved. In line 3, a new incumbent might be saved. Lines 8 to 24 perform the search.

\bigskip
\noindent
A pair is selected from the future (line 8) using some heuristic. Note that this pair is not removed from the future, and that P and T can be considered as pointers to sets. A pattern vertex is then selected, possibly using a heuristic (line 9). We now iterate over all possible target vertices in T (lines 10 to 21). A target vertex w is selected and a matching produced (line 11). A new future is created (using {\bf Let} to signify a new variable, line 12). Every pair in the future can now be split (lines 13 to 19) into pattern vertices adjacent to the selected pattern vertex v and target vertices adjacent to the selected target vertex w (lines 14 to 15) and this is added to the new future if both sets are not null (line 16) i.e. there is a potential for more matchings. This is then repeated symmetrically for non-adjacency (lines 17 to 19) using the compliments of the graphs.
A recursive call is then made using the new future and the increased matching (line 20). On return from that call we remove the matching (v,w) (line 21). Having explored all matchings with v in its target set we now consider what happens if the selected pattern vertex v is not matched (line 22 to 24), where that set of matchings does not contain a pair (v,*).

\bigskip
\bigskip
\bigskip
\bigskip
\noindent
Phew!

\section{Heuristics}



\section{Extensions}

So far, we have considered only unlabelled, undirected graphs. In this section, we
describe some straightforward changes to the algorithm that relax these restrictions.

For the case of unlabelled, directed graphs, each adjacency-matrix entry for a vertex
pair $(u,v)$ in graph $G$ or $H$ takes the value 0 if the vertices are not adjacent,
1 if there is an edge $u \rightarrow v$ but no edge $v \rightarrow u$, 2 if there is a
edge in the opposite direction, and 3 if there are edges in both directions. In lines
14-19 of the algorithm .......

Labelled, undirected .......

Labelled, directed ......

Connected ........

\section{Future Work}

Instead of branching on vertices in $\V(G)$, it would be equally valid to branch on
a vertex in $\V(H)$ in lines 9-23 of the algorithm, since our data structure treats the
two graphs symmetrically. More interestingly, we could choose which graph to branch on
at each search node using some heuristic (perhaps choosing based on whether the $P$ or
$T$ set is smaller).

We could create a hybrid of Lilybank and clique (for example, using Lilybank near the
top of the search tree, but switching to a clique encoding when fewer than some threshold
number of vertices remain to be selected). This might give us most of the benefits of
the clique encoding for labelled graphs, while avoiding the high memory cost and colouring
time of encoding the full instance.

\section{Computational Experiments}

Dual Xeon E5-2640 v2 CPUs, 64GBytes RAM. Parallel experiments 32 threads, using
all 16 physical cores with hyper-threading enabled.

\paragraph{No labels, undirected} are in \cref{figure:plain-cumulative}.

\paragraph{Vertex and edge labels, directed} are in \cref{figure:33ved-cumulative}.

\paragraph{Vertex and edge labels, not directed} are in \cref{figure:33ve-cumulative}, and are not in other papers so we should omit this unless we see something interesting.

\paragraph{No labels, undirected, connected} are in \cref{figure:plain-connected-cumulative}.

\paragraph{Vertex and edge labels, undirected, connected} are in \cref{figure:33ve-connected-cumulative}.

\paragraph{Large subgraph isomorphism instances} are in \cref{figure:sip-cumulative}.

\paragraph{Compared to CP FC} Nodes are in \cref{figure:plain-james-versus-cp-fc-nodes-scatter} and \cref{figure:33ved-james-versus-cp-fc-nodes-scatter}.

\paragraph{Nodes compared to kdown on SIP} are in \cref{figure:sip-james-versus-kdown-nodes-scatter}.

\begin{figure}
    \centering
    \includegraphics*{gen-graph-plain-cumulative.pdf}
    \caption{MCS Plain instances, cumulative runtimes}\label{figure:plain-cumulative}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-33ved-cumulative.pdf}
    \caption{MCS 33\% vertex and edge labelled directed instances, cumulative runtimes}\label{figure:33ved-cumulative}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-33ve-cumulative.pdf}
    \caption{MCS 33\% vertex and edge labelled undirected instances, cumulative runtimes}\label{figure:33ve-cumulative}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-plain-connected-cumulative.pdf}
    \caption{Unlabelled undirected instances, connected, cumulative runtimes}\label{figure:plain-connected-cumulative}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-33ve-connected-cumulative.pdf}
    \caption{MCS 33\% vertex and edge labelled undirected instances, connected, cumulative runtimes}\label{figure:33ve-connected-cumulative}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-sip-cumulative.pdf}
    \caption{SIP instances, cumulative runtimes}\label{figure:sip-cumulative}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-plain-james-versus-cp-fc-nodes-scatter.pdf}
    \caption{MCS Plain instances, James vs CP-FC, Nodes (TODO?? heatmapify this
    and exclude timeouts)}\label{figure:plain-james-versus-cp-fc-nodes-scatter}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-33ved-james-versus-cp-fc-nodes-scatter.pdf}
    \caption{MCS 33\% vertex and edge labelled directed instances, James vs
    CP-FC, Nodes (TODO?? heatmapify this and exclude
    timeouts)}\label{figure:33ved-james-versus-cp-fc-nodes-scatter}
\end{figure}

\begin{figure}
    \centering
    \includegraphics*{gen-graph-sip-james-versus-kdown-nodes-scatter.pdf}
    \caption{SIP instances, James vs kdown, Nodes (TODO?? heatmapify this and exclude
    timeouts)}\label{figure:sip-james-versus-kdown-nodes-scatter}
\end{figure}

\section{Conclusion}

\bibliographystyle{named}
\bibliography{paper}

\end{document}

